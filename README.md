# KUMOCRAWLER - Rocket.Chat Scraper Web Application (vibed by Gemini 2.5 Pro)

![PinkTeeToo](./static/mascot.jpg)

This application allows users to log into a publicly accessible Rocket.Chat instance, enumerate its channels, and scrape message history from selected channels. The results are compiled into a JSON file for download. This entire project was developed with iterative guidance and code generation from Gemini 2.5 Pro, following prompts from the user. The development journey log can be found here: https://g.co/gemini/share/e97af67b3f34

Mascot character #PinkTeeToo generated by Midjourney Niji-6.

**CRUCIAL: This application interacts with live websites and involves web scraping. Understand the following before use:**

1.  **CSS Selectors May Need Adjustment:**
    * The Python code (`scraper_logic.py`) uses CSS selectors to find elements (login fields, channel lists, messages, etc.). These selectors are based on common Rocket.Chat structures but **WILL LIKELY NEED TO BE ADJUSTED** for your specific target Rocket.Chat instance(s). Website structures change frequently. You will need to inspect the HTML of your target site and update the selectors accordingly if the scraper doesn't work as expected.
    * The current selectors are placeholders or examples based on typical Rocket.Chat layouts.

2.  **Anti-Scraping Measures (Cloudflare, etc.):**
    * Websites, especially those behind services like Cloudflare, employ anti-bot measures. While this scraper includes some "politeness" (delays, user-agent), **it may still be blocked, rate-limited, or presented with CAPTCHAs.**
    * Bypassing robust anti-scraping is a complex, ongoing challenge and often requires advanced techniques (e.g., proxy rotation, CAPTCHA solving services) not included here.
    * **Using this tool may lead to your IP address being temporarily or permanently banned by the target service.** Use responsibly.

3.  **Login and Credentials:**
    * You are entering Rocket.Chat credentials into this application. The application uses these credentials to log in programmatically.
    * Ensure the environment where you run this application (especially the Docker container and host) is secure.
    * The application does not store credentials persistently beyond the active scraping session (they are held in memory during a request).

4.  **Ethical and Legal Considerations:**
    * Always respect the terms of service of the website you are scraping.
    * Ensure you have the right to access and scrape the content. Scraping content behind a login has significant ethical and legal implications.
    * This tool is provided for educational and legitimate uses only. The developers are not responsible for misuse.

5.  **Resource Usage:**
    * Scraping, especially "entire history," can be resource-intensive for both your machine (running the headless browser) and the target server. Be mindful of this.

## Project Structure
.
├── app.py                # Quart backend application (main web framework file)
├── scraper_logic.py      # Playwright scraping functions
├── templates/
│   └── index.html        # Frontend HTML
├── static/
│   ├── script.js         # Frontend JavaScript
│   ├── style.css         # Basic CSS
│   └── mascot.jpg        # Mascot image (ensure filename matches)
├── Dockerfile            # Docker configuration
├── requirements.txt      # Python dependencies
├── .env.example          # Example for environment variables (mainly for local Quart dev)
└── README.md             # This file

## Setup and Running

**1. Prerequisites:**
    * Docker installed and running.
    * A web browser for inspecting elements if you need to adjust CSS selectors.

**2. Optional: Local Development Configuration (`.env` file):**
    * For local development *without Docker* (e.g., using `quart run` or `uvicorn app:app --reload`), you can create a `.env` file (copy from `.env.example`) to set Quart environment variables like `QUART_APP` and `QUART_ENV`.
    * When running *with Docker* as described below, Uvicorn's configuration is primarily set by the `CMD` in the `Dockerfile`.

**3. `requirements.txt`:**
    Ensure your `requirements.txt` includes `Quart` and `uvicorn` (and other dependencies like `playwright`, `python-dotenv`):
    ```txt
    Quart
    playwright>=1.30
    python-dotenv
    uvicorn
    ```

**4. `Dockerfile`:**
    Ensure your `Dockerfile` uses Uvicorn to run the Quart app. The `CMD` should be:
    ```dockerfile
    CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--port", "5000"]
    ```
    Also, remove or comment out any old `FLASK_...` environment variables from the `Dockerfile` as they are no longer used by Uvicorn/Quart.

**5. Build the Docker Image:**
    Navigate to the project's root directory in your terminal and run:
    ```bash
    docker build -t kumocrawler .
    ```

**5. Run the Docker Container:**
    ```bash
    docker run -p 5000:5000 --rm --shm-size="2g" kumocrawler
    ```
    * `--rm` automatically removes the container when it exits.
    * `--shm-size="2g"` provides more shared memory, which can be beneficial for headless browsers like Playwright. Adjust size as needed (e.g., "1g").
    * The application will be accessible at `http://localhost:5000`.

## How to Use

1.  Open your web browser and navigate to `http://localhost:5000`.
2.  Enter the full URL of the Rocket.Chat instance.
3.  Enter your username and password for that Rocket.Chat instance.
4.  Click "Connect & List Channels". The application will attempt to log in and enumerate channels.
    * You will see status updates and logs appearing live on the page.
    * If successful, a list of channels will appear.
5.  Choose your scraping depth:
    * "Scrape Entire History (1 channel max)"
    * "Scrape Last 3 Months (3 channels max)"
6.  Select the channel(s) using the checkboxes according to the chosen depth. The UI will enforce limits.
7.  Click "Start Scraping". (Note: The scraping endpoint may still need to be fully updated to the new Quart/SSE task pattern if it wasn't done during the framework switch).
8.  Once scraping is complete, a download link for the JSON file should appear.

## Customizing CSS Selectors

If the scraper fails to log in, list channels, or find messages, the most likely cause is that the CSS selectors in `scraper_logic.py` do not match the HTML structure of your target Rocket.Chat site.

1.  Open your target Rocket.Chat site in a regular browser.
2.  Use your browser's Developer Tools (usually F12, then "Inspect Element" or "Elements" tab).
3.  Manually perform the actions the scraper tries to do (login, find channel list, open a channel, find messages).
4.  Identify the correct CSS selectors for the elements listed in the `SELECTORS` dictionary within `scraper_logic.py`.
5.  Update the `SELECTORS` dictionary.

Good luck, and scrape responsibly!

